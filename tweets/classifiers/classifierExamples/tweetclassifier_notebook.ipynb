{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Classifier ##\n",
    "\n",
    "The following program determines the catagory to which input tweets belong. The catagories must be pre defined and their txt file paths sent to the super class constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\brookse/twitter_criteria.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8a96a7b98a87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtwittercriteria\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtwc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# Classification function imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\brookse\\twittercriteria.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# open criteria .yml file and load it into dictionary using yaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcriteria_yml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriteria_yml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mcriteria_yml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\brookse/twitter_criteria.yml'"
     ]
    }
   ],
   "source": [
    "# Author: Elizabeth Brooks\n",
    "# File: tweetclassifier.py\n",
    "# Date Modified: 07/14/2015\n",
    "# Edited: Hayden Fuss\n",
    "\n",
    "# Begin script\n",
    "\n",
    "# PreProcessor Directives\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import csv\n",
    "import yaml\n",
    "import re\n",
    "import random\n",
    "sys.path.append(os.path.realpath('../'))\n",
    "import twittercriteria as twc\n",
    "# Classification function imports\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# Global field declarations\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "# Define class to classify tweet relevance\n",
    "class TweetClassifier(object):\n",
    "    # Class constructor to initialize classifier\n",
    "    def __init__(self, paths, cleaner):\n",
    "        self.cleaner = cleaner\n",
    "        # Initialize data sets\n",
    "        self.categories = [] # Feature/Term, category/class set\n",
    "        self.tweets = [] # Tweet text/feature strings\n",
    "        self.labels = [] # Tweet categories/classes\n",
    "        # Begin functions for classification\n",
    "\t\t# Initialize classes using input txt file paths\n",
    "        self.initCategories(paths)\n",
    "        # Initialize the classifier specific pipelines\n",
    "\t\t# Classifier selected by the sub class object in use\n",
    "        self.initPipeline()\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End class constructor\n",
    "    \n",
    "    # Function to initialize the feature sets\n",
    "    def initCategories(self, paths):\n",
    "        self.categories = paths.keys()\n",
    "        # Loop through the txt files line by line\n",
    "        # Assign labels to tweets for sentiments in class paths\n",
    "        for category in paths.keys():\n",
    "            with open(current_dir + paths[category], \"r\") as trainingFile:\n",
    "                for line in trainingFile:\n",
    "                    self.tweets.append(line)\n",
    "                    self.labels.append(self.categories.index(category))\n",
    "        self.labels = np.array(self.labels)\n",
    "\t\t## The classifiers have to be fitted with two arrays: \n",
    "\t\t# \tan array X of size [n_samples, n_features] holding the training samples\n",
    "\t\t# \tand an array Y of size [n_samples] holding the target values (class labels) for the training samples\n",
    "        \n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "    # End initDictSet\n",
    "    \n",
    "    ## Function to build classifier pipeline\n",
    "    ## Default multinomial NB using chi squared statistics\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                      ('tfidf', TfidfTransformer()), # Perform TF-iFD weighting on features\n",
    "                      ('chi2', SelectKBest(chi2, k=2000)), # Use chi squared statistics to select the 1000 best features\n",
    "                      ('clf', MultinomialNB())]) # Use the multinomial NB classifier\n",
    "\n",
    "        # Fit the created multinomial NB classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "\n",
    "        # End func return statement\n",
    "        return\n",
    "    # End initPipeline\n",
    "\n",
    "    # Function to classify input tweet  \n",
    "    def classify(self, tweet_list):\n",
    "        # Clean the input list of tweets\n",
    "        for i in range(0,len(tweet_list)):\n",
    "            tweet_list[i] = self.cleaner(tweet_list[i])\n",
    "\n",
    "        # Return predicted class labels for samples in tweet_list\n",
    "        return self.classifier.predict(tweet_list)\n",
    "    # End classify func\n",
    "\t## Note: predict_log_proba method, log of probability estimates, is only available for log loss and modified Huber loss\n",
    "\t## This is because when loss=\"modified_huber\", probability estimates may be hard zeros and ones, \n",
    "\t# \tso taking the logarithm is not possible.\n",
    "\t## It returns the log-probability of the sample for each class in the model\n",
    "\t# \twhere classes are ordered as they are in self.classes_.\n",
    "\t## Note: predict_proba, probability estimates, is only available for log loss and modified Huber loss\n",
    "\t## This is because multi class probability estimates are derived from binary (one-versus-all, OVA) estimates \n",
    "\t# \tby simple normalization, as recommended by Zadrozny and Elkan.\n",
    "\t## It returns the mean accuracy on the given test data and labels\n",
    "\n",
    "    # Function to get the predicted classifiers confusion matrix\n",
    "    def getConfusionMatrix(self, actual, predicted):\n",
    "        print(metrics.classification_report(actual, predicted, target_names=self.categories))\n",
    "        # Return the confusion matrix\n",
    "        return metrics.confusion_matrix(actual,predicted)\n",
    "    # End getConfusionMatrix\n",
    "    \n",
    "    ## Function to perform a grid search for best features\n",
    "    ## GridSearchCV implements a \"fit\" method and a \"predict\" method like any classifier \n",
    "    #   except that the parameters of the classifier used to predict is optimized by cross-validation.\n",
    "    def getGridSearch(self):\n",
    "        # Set the search parameters\n",
    "        parameters = {'vect__ngram_range': [(1,1),(1,2)], # Try either words or bi grams\n",
    "                    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "                    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "                    'tfidf__use_idf': (True, False),\n",
    "                    'tfidf__norm': ('l1', 'l2'),\n",
    "                    'clf__alpha': (0.00001, 0.000001),\n",
    "                    'clf__penalty': ('l2', 'elasticnet', 'l1'),\n",
    "                    'clf__n_iter': (10, 50, 80),\n",
    "                    'clf__random_state':(0, 42)}\n",
    "        # Use all cores to create a grid search\n",
    "        classifierGS = GridSearchCV(self.pipeline, parameters, n_jobs=-1)\n",
    "        # Fit the CS estimator for use as a classifier\n",
    "        classifierGS = classifierGS.fit(self.tweets, self.labels)\n",
    "        # Get the scores using the GS classifier\n",
    "        bestParam, score, _ = max(classifierGS.grid_scores_, key=lambda x: x[1])\n",
    "        # Print the parameter values\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"%s: %r\" % (param_name,bestParam[param_name]))\n",
    "        # Print the classifier score\n",
    "        print(\"Classifier score: \" + str(score) + \"\\n\")\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End getGridSearch \n",
    "# End class TweetClassifier\n",
    "\n",
    "##########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sub classes of the above super class TweetClassifer differ only in the method of tweet classification, or catagorization. Therefore, the only function that needs to be overriden is the initPipeline(self) method, which initlializes the Pipeline of functions used to create a compound classifier for txt classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sub class to perform linear Multinomial NB tweet classification on transformed data\n",
    "class TweetClassifierMNB(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierMNB, self).__init__(paths, cleaner)\n",
    "        # End func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "        \n",
    "    # Overriding function to build the multinomial NB classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                                    ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                                    ('clf', MultinomialNB())]) # Use the multinomial NB classifier\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "        # Fit the created multinomial NB classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierMNB sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform linear support vector machine (SVM) tweet classification\n",
    "## SGDClassifier arg loss='hinge': (soft-margin) linear Support Vector Machine\n",
    "## Note: SGDClassifier supports multi class classification by combining multiple \n",
    "#\tbinary classifiers in a \"one versus all\" (OVA) scheme\n",
    "class TweetClassifierLinearSVM(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierLinearSVM, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the linear SVM classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(random_state=42))]) # Use the SVM classifier\n",
    "        ## The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "        ## By default, SGD supports a linear support vector machine (SVM) using the default args below\n",
    "        ## SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, n_iter=5, \n",
    "        #   shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', \n",
    "        #   eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False)\n",
    "\n",
    "        # Fit the created linear SVM classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierLinearSVM sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform quadratic support vector machine (SVM) tweet classification\n",
    "## SGDClassifier arg loss='squared_hinge' is like hinge, \n",
    "#\twhich is used for linear SVM, but is quadratically penalized.\n",
    "class TweetClassifierQuadraticSVM(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierQuadraticSVM, self).__init__(paths, cleaner)\n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the quadratic SVM classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer(max_df=0.5, ngram_range=(1,1))), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer(norm='l2', use_idf=True)), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='squared_hinge', random_state=42, n_iter=80, penalty='elasticnet', alpha=1e-05))]) # Use the quadratic SVM classifier\n",
    "        # The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\n",
    "        # Fit the created quadratic SVM classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierQuadraticSVM sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform less sensitive support vector machine (SVM) tweet classification\n",
    "## SGDClassifier arg loss='modified_huber' is another smooth loss that brings tolerance to \n",
    "#\toutliers as well as probability estimates.\n",
    "## Note: since they allow to create a probability model, loss=\"log\" \n",
    "#\tand loss=\"modified_huber\" are more suitable for OVA classification.\n",
    "class TweetClassifierModifiedSVM(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierModifiedSVM, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the smoothed SVM classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer(ngram_range=(1,1), max_df=0.5)), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer(norm='l2', use_idf=True)), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='modified_huber', random_state=0, penalty='l2', n_iter=80, alpha=1e-05))]) # Use the smoothed SVM classifier\n",
    "        # The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\n",
    "        # Fit the created smoothed SVM classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierModifiedSVM sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform logistic regression tweet classification\n",
    "## SGDClassifier arg loss='log' performs logistic regression\n",
    "## Note: since they allow to create a probability model, loss=\"log\" \n",
    "#\tand loss=\"modified_huber\" are more suitable for OVA classification.\n",
    "class TweetClassifierLogSVM(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierLogSVM, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the logistic regression classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='log'))]) # Use the logistic regression classifier\n",
    "        # The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\n",
    "        # Fit the created logistic regression classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierLogSVM sub class\n",
    "# Note: Using loss=\"log\" or loss=\"modified_huber\" enables the predict_proba method, \n",
    "#\twhich gives a vector of probability estimates per sample.\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform linear regression tweet classification\n",
    "## SGDClassifier arg loss='perceptron' is the linear loss used by the perceptron algorithm\n",
    "## Note: The perceptron algorithm is used for learning weights for features/terms\n",
    "class TweetClassifierPerceptronSVM(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierPerceptronSVM, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the perceptron algorithm using classifier via a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='perceptron'))]) # Use the perceptron algorithm for classification\n",
    "\t\t## The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\n",
    "        # Fit the created perceptron algorithm using classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierPerceptronSVM sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform linear regression tweet classification\n",
    "## SGDClassifier arg loss='huber' transforms the squared loss into a linear loss \n",
    "# \tover a certain distance, see epsilon arg description in initPipeline func below\n",
    "## SGDRegressor can also act as a linear SVR using the epsilon_insensitive loss \n",
    "# \tfunction or the slightly different squared_epsilon_insensitive (which penalizes outliers more)\n",
    "class TweetClassifierRegression(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierRegression, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the linear regression classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='huber', epsilon=0.1))]) # Use the linear regression classifier\n",
    "        ## The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\t\t## The epsilon arg in the epsilon-insensitive loss functions ('huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive')\n",
    "\t\t#\tFor 'huber' it determines the threshold at which it becomes less important to get the prediction exactly right.\n",
    "\n",
    "        # Fit the created linear regression classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierRegression sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform tweet classification with linear loss\n",
    "## SGDClassifier arg loss='squred_loss' allows for linear modelling similar to the default SGDRegressor\n",
    "class TweetClassifierLossSquared(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetClassifierLossSquared, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the linear loss classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDClassifier(loss='squared_loss'))]) # Use the classifier for linear loss\n",
    "        ## The SGD estimator implements regularized linear models with stochastic gradient descent learning\n",
    "\t\t\n",
    "        # Fit the created linear loss classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetClassifierLossSquared sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## Sub class to perform linear regression tweet classification\n",
    "## SGDRegressor is a linear model fitted by minimizing a regularized empirical loss with SGD\n",
    "## SGDRegressor mimics a linear regression using the squared_loss loss parameter and it can also act as\n",
    "# \ta linear SVR using the epsilon_insensitive loss function or the slightly different squared_epsilon_insensitive \n",
    "# \t(which penalizes outliers more)\n",
    "class TweetRegressor(TweetClassifier):\n",
    "    # Class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "        # Call the super class constructor which initializes the classifier\n",
    "        super(TweetRegressor, self).__init__(paths, cleaner)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End sub class constructor\n",
    "    \n",
    "    # Overriding function to build the regressor using a pipeline\n",
    "    def initPipeline(self):\n",
    "        # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', SGDRegressor())]) # Use the SGDRegressor classifier\n",
    "        ## The SGDRegressor estimator works with data represented as dense numpy arrays of floating point values for the features\n",
    "\t\t## SGDRegressor default mimics linear regression classification\n",
    "\t\t## SGDRegressor(loss='squared_loss', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, n_iter=5, \n",
    "\t\t# \tshuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, \n",
    "\t\t# \tpower_t=0.25, warm_start=False, average=False)\n",
    "\n",
    "        # Fit the created regressor\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "        # End of func return statement\n",
    "        return\n",
    "    # End initPipeline override\n",
    "# End TweetRegressor sub class\n",
    "## Note: SGD stands for Stochastic Gradient Descent, where the gradient of the loss is estimated each sample at a time \n",
    "# \tand the model is updated along the way with a decreasing strength schedule (aka learning rate)\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "# Sub class for creating a classifier for maximum entropy tweet analysis\n",
    "class TweetClassifierMaxEnt(TweetClassifier):\n",
    "\n",
    "\t# Sub class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "\t\t# Call the super class constructor\n",
    "        super(TweetClassifierMaxEnt, self).__init__(paths, cleaner)\n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "\t# End sub class constructor\n",
    "\t\t\n",
    "\t# Overriding function to build LogisticRegression classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "\t    # Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', LogisticRegression())]) # Use LogisticRegression as the estimator\n",
    "\t\t\t\t\t\t\t\n",
    "        # Fit the created LogisticRegression classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "\t# End initPipeline override\n",
    "# End TweetClassifierMaxEnt sub class\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "# Sub class for creating a Bernoulli NB classifier for tweet analysis\n",
    "class TweetClassifierBNB(TweetClassifier):\n",
    "\n",
    "\t# Sub class constructor\n",
    "    def __init__(self, paths, cleaner):\n",
    "\t\t# Call the super class constructor\n",
    "        super(TweetClassifierBNB, self).__init__(paths, cleaner)\n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "\t# End sub class constructor\n",
    "\t\t\n",
    "\t# Overriding function to build BernoulliNB classifier using a pipeline\n",
    "    def initPipeline(self):\n",
    "\t\t# Pipeline of transformers with a final estimator that behaves like a compound classifier\n",
    "        self.pipeline = Pipeline([('vect', CountVectorizer()), # Create a vector of feature frequencies\n",
    "                            ('tfidf', TfidfTransformer()), # Perform TF-iDF weighting on features\n",
    "                            ('clf', BernoulliNB())]) # Use the BernoulliNB classifier\n",
    "\t\t\t\t\t\t\t\n",
    "        # Fit the created BernoulliNB classifier\n",
    "        self.classifier = self.pipeline.fit(self.tweets, self.labels)\n",
    "\t\t# End of func return statement\n",
    "        return\n",
    "\t# End initPipeline override\n",
    "# End TweetClassifierBNB sub class\n",
    "\n",
    "# End script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
